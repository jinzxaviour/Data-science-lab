{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZsMgdc+1pzFAC5N0+wGam"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#load packages and modules\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#load data\n",
        "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()\n",
        "\n",
        "#preprocessing the data\n",
        "X_train =X_train.reshape(60000,784).astype('float32')\n",
        "X_valid =X_valid.reshape(10000,784).astype('float32')\n",
        "\n",
        "#normalization\n",
        "X_train /=255\n",
        "X_valid /=255\n",
        "\n",
        "X_valid[0]\n",
        "\n",
        "#convert the labels to one hot representation.\n",
        "from keras import utils as np_utils\n",
        "n_classes=10\n",
        "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_classes)\n",
        "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_classes)\n",
        "\n",
        "Y_valid[0]\n",
        "\n",
        "#Defining the model\n",
        "model=Sequential()\n",
        "\n",
        "#Adding dense layer\n",
        "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))\n",
        "\n",
        "#Adding the final layer\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#compile the network\n",
        "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])\n",
        "\n",
        "#train\n",
        "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
        "X_train, X_valid, Y_train,Y_valid = train_test_split(X, Y, stratify=Y)\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = clf.predict(X_valid)\n",
        "cm = confusion_matrix(Y_valid, Y_pred)\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2aS4cH0FdFiE",
        "outputId": "c82d1b81-b96a-4a10-e0ee-a8a8272ae06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.1182\n",
            "Epoch 2/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.1753\n",
            "Epoch 3/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.2167\n",
            "Epoch 4/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.2411\n",
            "Epoch 5/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.2580\n",
            "Epoch 6/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.2757\n",
            "Epoch 7/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.2938\n",
            "Epoch 8/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.3137\n",
            "Epoch 9/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.3333\n",
            "Epoch 10/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.3471\n",
            "Epoch 11/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.3611\n",
            "Epoch 12/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.3719\n",
            "Epoch 13/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.3825\n",
            "Epoch 14/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.3909\n",
            "Epoch 15/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.4006\n",
            "Epoch 16/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.4157\n",
            "Epoch 17/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.4378\n",
            "Epoch 18/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.4573\n",
            "Epoch 19/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.4725\n",
            "Epoch 20/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.4884\n",
            "Epoch 21/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.4989\n",
            "Epoch 22/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.5073\n",
            "Epoch 23/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.5174\n",
            "Epoch 24/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.5234\n",
            "Epoch 25/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.5286\n",
            "Epoch 26/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.5354\n",
            "Epoch 27/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.5395\n",
            "Epoch 28/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.5461\n",
            "Epoch 29/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.5502\n",
            "Epoch 30/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.5549\n",
            "Epoch 31/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.5601\n",
            "Epoch 32/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.5636\n",
            "Epoch 33/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.5682\n",
            "Epoch 34/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.5729\n",
            "Epoch 35/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.5757\n",
            "Epoch 36/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.5805\n",
            "Epoch 37/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.5838\n",
            "Epoch 38/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.5861\n",
            "Epoch 39/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.5903\n",
            "Epoch 40/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.5937\n",
            "Epoch 41/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.5960\n",
            "Epoch 42/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.5992\n",
            "Epoch 43/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.6026\n",
            "Epoch 44/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.6057\n",
            "Epoch 45/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.6081\n",
            "Epoch 46/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.6123\n",
            "Epoch 47/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.6151\n",
            "Epoch 48/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.6177\n",
            "Epoch 49/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.6211\n",
            "Epoch 50/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.6236\n",
            "Epoch 51/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.6263\n",
            "Epoch 52/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.6292\n",
            "Epoch 53/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.6318\n",
            "Epoch 54/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.6349\n",
            "Epoch 55/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.6378\n",
            "Epoch 56/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.6404\n",
            "Epoch 57/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.6431\n",
            "Epoch 58/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.6458\n",
            "Epoch 59/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.6485\n",
            "Epoch 60/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.6510\n",
            "Epoch 61/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.6533\n",
            "Epoch 62/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.6561\n",
            "Epoch 63/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.6582\n",
            "Epoch 64/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.6605\n",
            "Epoch 65/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.6625\n",
            "Epoch 66/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.6649\n",
            "Epoch 67/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.6668\n",
            "Epoch 68/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.6691\n",
            "Epoch 69/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.6712\n",
            "Epoch 70/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.6733\n",
            "Epoch 71/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.6753\n",
            "Epoch 72/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.6769\n",
            "Epoch 73/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.6786\n",
            "Epoch 74/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.6804\n",
            "Epoch 75/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.6820\n",
            "Epoch 76/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.6831\n",
            "Epoch 77/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.6845\n",
            "Epoch 78/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.6857\n",
            "Epoch 79/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.6872\n",
            "Epoch 80/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0553 - accuracy: 0.6884\n",
            "Epoch 81/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0549 - accuracy: 0.6894\n",
            "Epoch 82/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.6904\n",
            "Epoch 83/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.6923\n",
            "Epoch 84/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0537 - accuracy: 0.6931\n",
            "Epoch 85/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0533 - accuracy: 0.6942\n",
            "Epoch 86/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.6954\n",
            "Epoch 87/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.6964\n",
            "Epoch 88/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.6974\n",
            "Epoch 89/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.6981\n",
            "Epoch 90/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.6988\n",
            "Epoch 91/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.6996\n",
            "Epoch 92/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.7007\n",
            "Epoch 93/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.7016\n",
            "Epoch 94/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0501 - accuracy: 0.7022\n",
            "Epoch 95/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0498 - accuracy: 0.7032\n",
            "Epoch 96/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0494 - accuracy: 0.7041\n",
            "Epoch 97/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.7047\n",
            "Epoch 98/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0488 - accuracy: 0.7055\n",
            "Epoch 99/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0485 - accuracy: 0.7068\n",
            "Epoch 100/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.7081\n",
            "Epoch 101/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.7094\n",
            "Epoch 102/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0476 - accuracy: 0.7104\n",
            "Epoch 103/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0473 - accuracy: 0.7118\n",
            "Epoch 104/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.7137\n",
            "Epoch 105/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.7152\n",
            "Epoch 106/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.7168\n",
            "Epoch 107/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0461 - accuracy: 0.7188\n",
            "Epoch 108/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.7208\n",
            "Epoch 109/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.7232\n",
            "Epoch 110/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0453 - accuracy: 0.7252\n",
            "Epoch 111/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.7279\n",
            "Epoch 112/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.7299\n",
            "Epoch 113/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.7325\n",
            "Epoch 114/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.7348\n",
            "Epoch 115/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.7365\n",
            "Epoch 116/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0438 - accuracy: 0.7399\n",
            "Epoch 117/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0435 - accuracy: 0.7425\n",
            "Epoch 118/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.7450\n",
            "Epoch 119/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.7466\n",
            "Epoch 120/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.7502\n",
            "Epoch 121/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0426 - accuracy: 0.7517\n",
            "Epoch 122/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.7545\n",
            "Epoch 123/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0422 - accuracy: 0.7562\n",
            "Epoch 124/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0420 - accuracy: 0.7582\n",
            "Epoch 125/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0417 - accuracy: 0.7603\n",
            "Epoch 126/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.7617\n",
            "Epoch 127/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.7636\n",
            "Epoch 128/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.7650\n",
            "Epoch 129/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.7670\n",
            "Epoch 130/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0407 - accuracy: 0.7686\n",
            "Epoch 131/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.7703\n",
            "Epoch 132/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0403 - accuracy: 0.7715\n",
            "Epoch 133/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.7728\n",
            "Epoch 134/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.7738\n",
            "Epoch 135/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0397 - accuracy: 0.7751\n",
            "Epoch 136/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.7759\n",
            "Epoch 137/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.7774\n",
            "Epoch 138/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.7784\n",
            "Epoch 139/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.7792\n",
            "Epoch 140/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.7800\n",
            "Epoch 141/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.7812\n",
            "Epoch 142/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.7818\n",
            "Epoch 143/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.7825\n",
            "Epoch 144/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.7835\n",
            "Epoch 145/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.7838\n",
            "Epoch 146/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.7845\n",
            "Epoch 147/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.7850\n",
            "Epoch 148/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0374 - accuracy: 0.7856\n",
            "Epoch 149/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.7862\n",
            "Epoch 150/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.7868\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}